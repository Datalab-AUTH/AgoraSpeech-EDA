{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook applies basic preprocessing actions to the final AgoraSpeech dataset.\n",
    "\n",
    "* Input: 'AgoraSpeech.csv'\n",
    "* Output: 'AgoraSpeech_preprocessed.csv'\n",
    "* Actions: \n",
    "    1. Convert continuous features (sentiment, polarization, populism) into categorical features based on specific mapping in each case\n",
    "    2. Factorize 'elections'\n",
    "    3. Extract from the named entities list of lists, the specific entities recognized and their respective categories, creating two additional columns for each case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5279 entries, 0 to 5278\n",
      "Data columns (total 20 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   elections                  5279 non-null   object \n",
      " 1   speech_id                  5279 non-null   object \n",
      " 2   politician                 5279 non-null   object \n",
      " 3   date (YYYY-MM-DD)          5279 non-null   object \n",
      " 4   location                   5279 non-null   object \n",
      " 5   paragraph                  5279 non-null   int64  \n",
      " 6   text                       5279 non-null   object \n",
      " 7   text_el                    5279 non-null   object \n",
      " 8   criticism_or_agenda_gpt    5139 non-null   object \n",
      " 9   topic_gpt                  5180 non-null   object \n",
      " 10  sentiment_gpt              5185 non-null   float64\n",
      " 11  polarization_gpt           5184 non-null   float64\n",
      " 12  populism_gpt               5184 non-null   float64\n",
      " 13  named entities_gpt         5236 non-null   object \n",
      " 14  criticism_or_agenda_human  5279 non-null   object \n",
      " 15  topic_human                5277 non-null   object \n",
      " 16  sentiment_human            4936 non-null   float64\n",
      " 17  polarization_human         5277 non-null   float64\n",
      " 18  populism_human             5272 non-null   float64\n",
      " 19  named entities_human       5279 non-null   object \n",
      "dtypes: float64(6), int64(1), object(13)\n",
      "memory usage: 825.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# read the final dataset\n",
    "data = pd.read_csv('AgoraSpeech.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert continuous features (sentiment, polarization, populism) into categorical features based on specific mapping in each case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reusable mapping function\n",
    "def mapping_function(value, boundaries, values):\n",
    "    for i, boundary in enumerate(boundaries):\n",
    "        if value <= boundary:\n",
    "            return values[i]\n",
    "    return values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SENTIMENT: [-1, -0.34] -> negative , [-0.33, 0.33] -> neutral, [0.34, 1] -> positive\n",
    "boundaries = [-0.34, 0.33]\n",
    "categories = ['negative', 'neutral', 'positive']\n",
    "data['sentiment_human_category'] = data['sentiment_human'].apply(lambda x: mapping_function(x, boundaries, categories) if not pd.isna(x) else np.nan)\n",
    "data['sentiment_gpt_category'] = data['sentiment_gpt'].apply(lambda x: mapping_function(x, boundaries, categories) if not pd.isna(x) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POLARIZATION: [0, 0.5] -> low , [0.51, 0.8] -> medium, [0.81, 1] -> high\n",
    "categories = ['low', 'medium', 'high']\n",
    "boundaries = [0.5, 0.8]\n",
    "data['polarization_human_category'] = data['polarization_human'].apply(lambda x: mapping_function(x, boundaries, categories) if not pd.isna(x) else np.nan)\n",
    "data['polarization_gpt_category'] = data['polarization_gpt'].apply(lambda x: mapping_function(x, boundaries, categories) if not pd.isna(x) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POPULISM: [0, 0.5] -> 0 -> low , [0.51, 0.8] -> 1 -> medium, [0.81, 1] -> 2 -> high\n",
    "data['populism_human_category'] = data['populism_human'].apply(lambda x: mapping_function(x, boundaries, categories) if not pd.isna(x) else np.nan)\n",
    "data['populism_gpt_category'] = data['populism_gpt'].apply(lambda x: mapping_function(x, boundaries, categories) if not pd.isna(x) else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factorize 'elections'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['elections'], unique_labels = pd.factorize(data['elections'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract from the named entities list of lists, the specific entities recognized and their respective categories, creating two additional columns for each case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def named_entities_extraction(df, col_name, new_col_name_chat_data, ith_el):\n",
    "    entities_list = ['organization', 'group of people', 'location', 'person', 'country', 'date', 'political party']\n",
    "\n",
    "    if df[col_name].dtype == str:\n",
    "        df[col_name] = df[col_name].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "    df[new_col_name_chat_data] = ''\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        if pd.isna(row[col_name]):\n",
    "            continue\n",
    "        entity_lists = ast.literal_eval(row[col_name])\n",
    "        new_el = []\n",
    "        for sublist in entity_lists:\n",
    "            if len(sublist) >= ith_el:\n",
    "                new_el.append(sublist[ith_el - 1])\n",
    "        df.at[i, new_col_name_chat_data] = new_el\n",
    "\n",
    "    if new_col_name_chat_data == 'entity_category':\n",
    "        df[new_col_name_chat_data] = df[new_col_name_chat_data].apply(lambda x: [val if val in entities_list else 'other' for val in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_entities_extraction(data, 'named entities_human', 'entity_specific_human', 1)\n",
    "named_entities_extraction(data, 'named entities_human', 'entity_category_human', 2)\n",
    "named_entities_extraction(data, 'named entities_gpt', 'entity_specific_gpt', 1)\n",
    "named_entities_extraction(data, 'named entities_gpt', 'entity_category_gpt', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('AgoraSpeech_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "elections                        0\n",
       "speech_id                        0\n",
       "politician                       0\n",
       "date (YYYY-MM-DD)                0\n",
       "location                         0\n",
       "paragraph                        0\n",
       "text                             0\n",
       "text_el                          0\n",
       "criticism_or_agenda_gpt        140\n",
       "topic_gpt                       99\n",
       "sentiment_gpt                   94\n",
       "polarization_gpt                95\n",
       "populism_gpt                    95\n",
       "named entities_gpt              43\n",
       "criticism_or_agenda_human        0\n",
       "topic_human                      2\n",
       "sentiment_human                343\n",
       "polarization_human               2\n",
       "populism_human                   7\n",
       "named entities_human             0\n",
       "sentiment_human_category       343\n",
       "sentiment_gpt_category          94\n",
       "polarization_human_category      2\n",
       "polarization_gpt_category       95\n",
       "populism_human_category          7\n",
       "populism_gpt_category           95\n",
       "entity_specific_human            0\n",
       "entity_category_human            0\n",
       "entity_specific_gpt              0\n",
       "entity_category_gpt              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find number of missing data per column\n",
    "data.isnull().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
